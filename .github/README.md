# ğŸ¤– GitHub Actions Workflows

Acest folder conÈ›ine workflow-uri GitHub Actions pentru automatizarea scraping-ului.

## ğŸ“‹ Workflow-uri disponibile

### 1. `scrape-daily.yml` - Scraping automat zilnic

**Trigger:** Zilnic la 06:00 UTC (08:00 Romanian time)

**Ce face:**
- RuleazÄƒ scraper-ul automat Ã®n fiecare zi
- SalveazÄƒ rezultatele ca artifacts (pÄƒstrate 90 zile)
- Commit automat rezultatele Ã®n folder `data/`
- OrganizeazÄƒ datele pe an/lunÄƒ

**Rulare manualÄƒ:**
- Mergi la tab-ul "Actions" pe GitHub
- SelecteazÄƒ "Scrape AFDJ Daily"
- Click "Run workflow"

---

### 2. `scrape-on-demand.yml` - Scraping la cerere

**Trigger:** Manual (prin GitHub UI)

**Ce face:**
- Permite rulare manualÄƒ cu opÈ›iuni personalizate
- Alege formatul de export (json, csv, excel, all)
- SalveazÄƒ rezultatele ca artifacts (pÄƒstrate 30 zile)
- AfiÈ™eazÄƒ rezumat Ã®n GitHub UI

**Cum sÄƒ rulezi:**
1. Mergi la tab-ul "Actions"
2. SelecteazÄƒ "Scrape AFDJ On-Demand"
3. Click "Run workflow"
4. Alege formatul dorit
5. Click "Run workflow" verde

---

### 3. `test-scraper.yml` - Testare automatÄƒ

**Trigger:** 
- La fiecare push pe `main` sau `develop`
- La fiecare pull request
- Manual

**Ce face:**
- TesteazÄƒ scraper-ul pe Python 3.9, 3.10, 3.11, 3.12
- VerificÄƒ dacÄƒ scraper-ul se iniÈ›ializeazÄƒ corect
- ÃncearcÄƒ sÄƒ facÄƒ scraping (cu timeout)
- SalveazÄƒ rezultatele pentru debugging

---

## ğŸ“Š Cum sÄƒ vezi rezultatele

### Artifacts (FiÈ™iere generate)

1. Mergi la tab-ul "Actions"
2. Click pe un workflow run
3. Scroll jos la secÈ›iunea "Artifacts"
4. Download ZIP-ul cu rezultatele

### Date istorice (dacÄƒ ai activat commit-ul)

Datele sunt salvate Ã®n:
```
data/
â”œâ”€â”€ 2026/
â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”œâ”€â”€ cote_dunare_20260128.json
â”‚   â”‚   â””â”€â”€ cote_dunare_20260129.json
â”‚   â””â”€â”€ 02/
â”‚       â””â”€â”€ ...
```

---

## âš™ï¸ Configurare

### Activare workflow-uri

Workflow-urile se activeazÄƒ automat cÃ¢nd le push-ui pe GitHub.

### Dezactivare workflow

DacÄƒ nu vrei sÄƒ ruleze automat:
1. Mergi la `.github/workflows/scrape-daily.yml`
2. È˜terge sau comenteazÄƒ secÈ›iunea `schedule:`
3. Commit È™i push

### Modificare orar

Pentru a schimba ora de rulare:
```yaml
schedule:
  # Format: minute hour * * *
  # Exemplu pentru 10:00 UTC:
  - cron: '0 10 * * *'
```

### Modificare frecvenÈ›Äƒ

```yaml
# RuleazÄƒ la fiecare 6 ore
- cron: '0 */6 * * *'

# RuleazÄƒ doar Luni-Vineri
- cron: '0 6 * * 1-5'

# RuleazÄƒ de 2 ori pe zi (06:00 È™i 18:00)
- cron: '0 6,18 * * *'
```

---

## ğŸ” Permissions

Workflow-urile au nevoie de:
- âœ… `contents: write` - pentru commit automat
- âœ… `actions: write` - pentru artifacts

Aceste permisiuni sunt configurate automat de GitHub.

---

## ğŸ“ NotificÄƒri

Pentru a primi notificÄƒri cÃ¢nd workflow-urile eÈ™ueazÄƒ:

1. Mergi la Settings â†’ Notifications
2. SecÈ›iunea "Actions"
3. BifeazÄƒ "Send notifications for failed workflows"

---

## ğŸ› Debugging

DacÄƒ un workflow eÈ™ueazÄƒ:

1. Click pe workflow-ul roÈ™u
2. Click pe job-ul care a eÈ™uat
3. ExpandeazÄƒ step-ul cu eroare
4. Vezi log-urile complete

Tips:
- DacÄƒ AFDJ e down, workflow-ul va eÈ™ua (normal)
- Cloudflare blocking poate cauza erori
- VerificÄƒ artifacts pentru rezultate parÈ›iale

---

## ğŸ’¡ Use Cases

### 1. Monitorizare continuÄƒ
FoloseÈ™te `scrape-daily.yml` pentru colectare automatÄƒ de date

### 2. AnalizÄƒ punctualÄƒ
FoloseÈ™te `scrape-on-demand.yml` cÃ¢nd vrei date fresh acum

### 3. Development
FoloseÈ™te `test-scraper.yml` pentru a testa modificÄƒrile

---

## ğŸš€ Workflow avansat (opÈ›ional)

Pentru notificÄƒri Telegram/Email cÃ¢nd sunt cote critice:

```yaml
- name: Check for alerts
  run: |
    python examples/alerts_system.py
    
- name: Send notification
  if: failure()
  # AdaugÄƒ aici logica de notificare
```

---

**ğŸŒŠ Happy Scraping! ğŸš¢**
