name: Actualizare Zilnica Cote Dunare

on:
  schedule:
    # Rulează la 09:45 ora României (07:45 UTC)
    - cron: '45 7 * * *'
  workflow_dispatch: # Permite declanșarea manuală din interfața GitHub

jobs:
  scrape_job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configurare Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Instalare dependente
        run: |
          pip install pdfplumber pandas requests

      - name: Descarcare PDF (Tentativa prin Proxy)
        run: |
          # Încercăm să descărcăm prin allorigins.win pentru a masca IP-ul de GitHub
          # Dacă acesta eșuează, scriptul va încerca direct în pasul următor
          curl -L "https://api.allorigins.win/raw?url=https://www.afdj.ro/sites/default/files/bhcote.pdf" \
               -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" \
               -o cote_dunare.pdf || echo "Download-ul prin proxy a esuat, verificam in scraper.py"

      - name: Rulare Scraper Python
        run: python scraper.py

      - name: Commit si Push date noi
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          # Adăugăm fișierele CSV generate de scraper.py
          git add cote_porturi.csv date_climatice.csv || true
          # Facem commit doar dacă există modificări
          git commit -m "Actualizare date AFDJ - $(date +'%Y-%m-%d')" || exit 0
          git push
