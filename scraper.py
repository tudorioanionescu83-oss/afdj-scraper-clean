# ... (pÄƒstreazÄƒ imports + STATIONS + insert_data)

def scrape_afdj():
    print(f"ğŸš€ DEBUG AFDJ - {datetime.now()}")
    r = requests.get(AFDJ_URL)
    soup = BeautifulSoup(r.text, 'html.parser')
    
    # DEBUG: Toate tabelele de pe paginÄƒ!
    all_tables = soup.find_all('table')
    print(f"ğŸ“Š GÄƒsite {len(all_tables)} tabele:")
    for i, table in enumerate(all_tables):
        text_preview = table.get_text()[:200]
        print(f"  Tabel {i}: {text_preview}...")
        if 'Galati' in text_preview or 'Tulcea' in text_preview:
            print(f"  ğŸ¯ Tabel {i} CANDIDAT!")
    
    # Ia PRIMUL tabel care conÈ›ine 'Galati'
    table = None
    for t in all_tables:
        if 'Galati' in t.get_text():
            table = t
            print("âœ… Tabel SELECTAT!")
            break
    
    if not table:
        print("âŒ NICIUN tabel cu 'Galati'!")
        return
    
    # Restul codului tÄƒu (rows, parsing...)
    rows = table.find_all('tr')[1:]
    # ... (pÄƒstreazÄƒ parsing-ul exact)
