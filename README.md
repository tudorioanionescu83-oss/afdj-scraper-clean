# ğŸŒŠ AFDJ DunÄƒrea - Scraper Suite Complet

SoluÈ›ie completÄƒ pentru extragerea datelor despre **cotele DunÄƒrii** de pe site-ul AFDJ.ro (AdministraÈ›ia FluvialÄƒ a DunÄƒrii de Jos).

## ğŸ“‹ Ce date extrage?

Pentru fiecare din cele **23 de porturi** de pe DunÄƒre:

âœ… **Date actuale:**
- Localitate (Sulina, Tulcea, GalaÈ›i, etc.)
- Kilometraj de la gura DunÄƒrii
- **Cota apei** Ã®n centimetri
- **VariaÈ›ia** faÈ›Äƒ de ziua precedentÄƒ
- **TendinÈ›a** (creÈ™tere/scÄƒdere/stabil)
- **Temperatura apei** Ã®n grade Celsius
- Data actualizÄƒrii

âœ… **Prognoze:**
- Prognoza la 24h
- Prognoza la 48h
- Prognoza la 72h
- Prognoza la 96h
- Prognoza la 120h (5 zile)
- Data actualizÄƒrii prognozelor

---

## ğŸš€ Quick Start

### Instalare dependinÈ›e:

```bash
# Pentru scraper simplu (RECOMAND SÄ‚ ÃNCEPI CU ACESTA)
pip install requests beautifulsoup4 pandas openpyxl lxml

# Pentru Selenium (dacÄƒ primul nu funcÈ›ioneazÄƒ din cauza Cloudflare)
pip install selenium undetected-chromedriver pandas
```

### Rulare:

```bash
# Metoda 1: Scraper simplu (Ã®ncercÄƒ prima datÄƒ)
python afdj_final_scraper.py

# Metoda 2: Cu Selenium (dacÄƒ Metoda 1 e blocatÄƒ de Cloudflare)
python afdj_selenium_scraper.py
```

### Output:

```
ğŸ“‚ cote_dunare.json   - Date Ã®n format JSON
ğŸ“‚ cote_dunare.csv    - Date Ã®n format CSV
ğŸ“‚ cote_dunare.xlsx   - Date Ã®n format Excel
```

---

## ğŸ“¦ FiÈ™iere incluse

### 1. `afdj_final_scraper.py` â­ **RECOMAND**

**Scraper simplu cu requests + BeautifulSoup**

âœ… Avantaje:
- Rapid È™i eficient
- Nu necesitÄƒ browser
- Consum redus de resurse
- Cod simplu de Ã®nÈ›eles

âŒ Dezavantaje:
- Poate fi blocat de Cloudflare

**Utilizare:**
```python
from afdj_final_scraper import AFDJCoteScraper

scraper = AFDJCoteScraper()
data = scraper.scrape(export_format='all')  # json, csv, excel, sau all
```

---

### 2. `afdj_selenium_scraper.py` ğŸš€ **PENTRU CLOUDFLARE**

**Scraper cu Selenium pentru bypass Cloudflare**

âœ… Avantaje:
- Bypass automat Cloudflare
- FuncÈ›ioneazÄƒ pentru pagini JavaScript complexe
- Poate face screenshot pentru debugging

âŒ Dezavantaje:
- Mai lent (trebuie sÄƒ Ã®ncarce browser)
- NecesitÄƒ Chrome instalat
- Consum mai mare de resurse

**Utilizare:**
```python
from afdj_selenium_scraper import AFDJSeleniumScraper

scraper = AFDJSeleniumScraper(headless=True)
data = scraper.scrape(save_screenshot=True)
```

---

### 3. `data_structure_examples.py` ğŸ“š **DOCUMENTAÈšIE**

**Exemple È™i documentaÈ›ie completÄƒ**

ConÈ›ine:
- Structura detaliatÄƒ a datelor
- Exemple de analizÄƒ
- Exemple de export grafic
- Integrare cu baze de date
- API REST cu Flask
- NotificÄƒri Telegram
- Sistem de alertÄƒ pentru cote critice

---

## ğŸ“Š Structura datelor

### Exemplu JSON output:

```json
{
  "source": "AFDJ",
  "url": "https://www.afdj.ro/ro/cotele-dunarii",
  "timestamp": "2026-01-28T10:30:00",
  "count": 23,
  "ports": [
    {
      "localitate": "Sulina",
      "km": 0,
      "cota_cm": 80,
      "cota_text": "80 cm",
      "variatia_cm": -12,
      "tendinta": "scÄƒdere",
      "temperatura_celsius": 2.0,
      "temperatura_text": "2,0 Â°C",
      "data_actualizare": "28/01/2026",
      "prognoza_24h": "scÄƒdere 5-15 cm",
      "prognoza_48h": "scÄƒdere 10-20 cm",
      "prognoza_72h": "scÄƒdere 5-15 cm",
      "prognoza_96h": "stabilizare",
      "prognoza_120h": "stabilizare",
      "data_actualizare_prognoze": "27/01/2026",
      "timestamp_scraping": "2026-01-28T10:30:00.123456"
    },
    ...
  ]
}
```

---

## ğŸ¯ Cazuri de utilizare

### 1. Monitorizare simplÄƒ

```python
from afdj_final_scraper import AFDJCoteScraper

scraper = AFDJCoteScraper()
data = scraper.scrape()

# GÄƒseÈ™te cota maximÄƒ
max_port = max(data, key=lambda x: x['cota_cm'])
print(f"Cea mai mare cotÄƒ: {max_port['localitate']} - {max_port['cota_cm']} cm")
```

### 2. Salvare Ã®n bazÄƒ de date

```python
import sqlite3
import pandas as pd

# RuleazÄƒ scraper
data = scraper.scrape()
df = pd.DataFrame(data)

# SalveazÄƒ Ã®n SQLite
conn = sqlite3.connect('cote_dunare.db')
df.to_sql('cote', conn, if_exists='append', index=False)
conn.close()
```

### 3. Sistem de alertÄƒ

```python
COTE_ATENTIE = {'Sulina': 250, 'Tulcea': 550, 'GalaÈ›i': 650}

data = scraper.scrape()
for port in data:
    if port['localitate'] in COTE_ATENTIE:
        if port['cota_cm'] >= COTE_ATENTIE[port['localitate']]:
            print(f"ğŸš¨ ALERTÄ‚: {port['localitate']} - CotÄƒ de atenÈ›ie depÄƒÈ™itÄƒ!")
```

### 4. Grafic cu evoluÈ›ia cotelor

```python
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('cote_dunare.csv')
df_sorted = df.sort_values('km')

plt.figure(figsize=(15, 6))
plt.plot(df_sorted['km'], df_sorted['cota_cm'], marker='o')
plt.xlabel('Kilometraj (km)')
plt.ylabel('Cota (cm)')
plt.title('Cotele DunÄƒrii')
plt.grid(True)
plt.savefig('cote_grafic.png')
```

### 5. API REST cu Flask

```python
from flask import Flask, jsonify
import pandas as pd

app = Flask(__name__)

@app.route('/api/cote')
def get_cote():
    df = pd.read_csv('cote_dunare.csv')
    return jsonify(df.to_dict(orient='records'))

@app.route('/api/cote/<localitate>')
def get_cota_port(localitate):
    df = pd.read_csv('cote_dunare.csv')
    port = df[df['localitate'] == localitate]
    return jsonify(port.iloc[0].to_dict())

app.run(port=5000)
```

---

## ğŸ”„ Automatizare

### Cron job (Linux/Mac) - rulare zilnicÄƒ la 06:00

```bash
crontab -e

# AdaugÄƒ:
0 6 * * * cd /path/to/scraper && python3 afdj_final_scraper.py
```

### Task Scheduler (Windows)

```powershell
# PowerShell script: run_scraper.ps1
cd C:\path\to\scraper
python afdj_final_scraper.py

# CreeazÄƒ task Ã®n Task Scheduler:
# - Trigger: Daily la 06:00
# - Action: Run powershell.exe -File run_scraper.ps1
```

### Python script cu schedule

```python
import schedule
import time
from afdj_final_scraper import AFDJCoteScraper

def job():
    print("Running scraper...")
    scraper = AFDJCoteScraper()
    scraper.scrape()
    print("Done!")

# RuleazÄƒ Ã®n fiecare zi la 06:00
schedule.every().day.at("06:00").do(job)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

## ğŸ› Troubleshooting

### Problema: "Failed to download page" sau Cloudflare blocking

**SoluÈ›ie 1:** FoloseÈ™te Selenium scraper-ul
```bash
python afdj_selenium_scraper.py
```

**SoluÈ›ie 2:** AdaugÄƒ delay Ã®ntre request-uri
```python
import time
time.sleep(5)  # AÈ™teaptÄƒ 5 secunde Ã®nainte de fiecare request
```

**SoluÈ›ie 3:** FoloseÈ™te un VPN sau proxy

### Problema: "No data found in page"

**Cauze posibile:**
1. Structura HTML-ului s-a schimbat
2. Site-ul e offline
3. Cloudflare blocking

**SoluÈ›ie:** VerificÄƒ manual pagina Ã®n browser È™i comparÄƒ cu codul scraper-ului

### Problema: Selenium - "Chrome not found"

**SoluÈ›ie:**
```bash
# InstaleazÄƒ Chrome
# Ubuntu/Debian:
wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
sudo dpkg -i google-chrome-stable_current_amd64.deb

# MacOS:
brew install --cask google-chrome

# Windows: DescarcÄƒ de pe google.com/chrome
```

---

## ğŸ“ˆ Performance

### afdj_final_scraper.py (requests)
- âš¡ Timp execuÈ›ie: ~2-5 secunde
- ğŸ’¾ Memorie: ~50 MB
- ğŸŒ Network: 1 request HTTP

### afdj_selenium_scraper.py
- â±ï¸ Timp execuÈ›ie: ~10-15 secunde
- ğŸ’¾ Memorie: ~200-300 MB
- ğŸŒ Network: Multiple requests + JavaScript

---

## ğŸ” ConsideraÈ›ii legale

- Datele de pe AFDJ.ro sunt **publice**
- Scraping-ul este permis pentru **uz personal/cercetare**
- **NU** face request-uri prea frecvente (max 1/minut)
- **NU** folosi datele comercial fÄƒrÄƒ permisiune
- RespectÄƒ `robots.txt` È™i Terms of Service

---

## ğŸ¤ ContribuÈ›ii

ÃmbunÄƒtÄƒÈ›iri sugerate:
- [ ] AdÄƒugare istoricizare date (database time-series)
- [ ] Dashboard web cu Streamlit/Dash
- [ ] NotificÄƒri email/SMS pentru alerte
- [ ] PredicÈ›ii ML pentru evoluÈ›ia cotelor
- [ ] ComparaÈ›ie cu date meteo

---

## ğŸ“ Support

DacÄƒ Ã®ntÃ¢mpini probleme:

1. **VerificÄƒ** cÄƒ ai toate dependinÈ›ele instalate
2. **TesteazÄƒ** manual site-ul AFDJ Ã®n browser
3. **ÃncearcÄƒ** Selenium scraper-ul dacÄƒ primul nu funcÈ›ioneazÄƒ
4. **VerificÄƒ** cÄƒ ai internet funcÈ›ional

---

## ğŸ“ Changelog

### v1.0 - 28.01.2026
- âœ… Scraper initial cu requests + BeautifulSoup
- âœ… Scraper alternativ cu Selenium
- âœ… Extragere date complete (cote + prognoze)
- âœ… Export Ã®n JSON, CSV, Excel
- âœ… DocumentaÈ›ie completÄƒ
- âœ… Exemple de utilizare

---

## â­ Quick Reference

```bash
# Instalare
pip install requests beautifulsoup4 pandas openpyxl lxml

# Rulare simplÄƒ
python afdj_final_scraper.py

# Rulare cu Selenium (pentru Cloudflare)
pip install selenium undetected-chromedriver
python afdj_selenium_scraper.py

# Verificare output
cat cote_dunare.json
# sau
import pandas as pd
df = pd.read_csv('cote_dunare.csv')
print(df.head())
```

---

**ğŸŒŠ Succes la monitorizarea DunÄƒrii! ğŸš¢**
